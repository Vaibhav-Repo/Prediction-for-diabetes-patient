{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0006ee84",
   "metadata": {},
   "source": [
    "## step1:import related dependencies(libraries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe9e6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad952ba",
   "metadata": {},
   "source": [
    "## step2 : loading the data using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b2cf72",
   "metadata": {},
   "source": [
    "#### we can get data from any govt orgs or internet or ngos...etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8087f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('pima-data (1).xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d64a1aa",
   "metadata": {},
   "source": [
    "## step3: cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0406f6c4",
   "metadata": {},
   "source": [
    "#### a . checking the null values present in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "# has_diabetes    0 if o means we dont have any null values in a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f98474aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if null values are presemt then we have to use dropna or fillna\n",
    "## if you have more data then use dropna otherwise fillna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6433f3",
   "metadata": {},
   "source": [
    "### b . finding the corelation between two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "fig,ax= plt.subplots(figsize=(12,12))\n",
    "cmap = 'plasma'\n",
    "ax.matshow(corr,cmap=cmap)\n",
    "plt.xticks(range(len(corr.columns)),corr.columns,rotation=60)\n",
    "plt.yticks(range(len(corr.columns)),corr.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec4e7d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('thickness',axis=1,inplace=True)\n",
    "df.drop('has_diabetes',axis=1,inplace=True)\n",
    "df.drop('diabetes_orig',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1587ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "fig,ax= plt.subplots(figsize=(12,12))\n",
    "cmap = 'plasma'\n",
    "ax.matshow(corr,cmap=cmap)\n",
    "plt.xticks(range(len(corr.columns)),corr.columns,rotation=60)\n",
    "plt.yticks(range(len(corr.columns)),corr.columns)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964bb8c7",
   "metadata": {},
   "source": [
    "### d. replacing the string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4122ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to convert True to 1 and False to 0\n",
    "# Want to replace True and false in diabetes columns\n",
    "dict1 = {\n",
    "'diabetes':[True,False]\n",
    "}\n",
    "\n",
    "# Inplace of True place with 1 and in place of False place with 0\n",
    "dict2 = {\n",
    "'diabetes':[1,0]\n",
    "}\n",
    "\n",
    "df.replace(dict1,dict2,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f1b0aa",
   "metadata": {},
   "source": [
    "### checking the propertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d23790",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_true = len(df.loc[df['diabetes']==1])\n",
    "num_false = len(df.loc[df['diabetes'] == 0])\n",
    "print(f'num_true = {num_true}')\n",
    "print(f'num_false = {num_false}')\n",
    "per_num_true = (num_true / (num_true+num_false))*100\n",
    "print(per_num_true)\n",
    "per_num_false = (num_false/(num_false+num_true))*100\n",
    "print(per_num_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c277a",
   "metadata": {},
   "source": [
    "### if we observer 65:35 is a good percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4 train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db21e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "input_columns = ['num_preg','glucose_conc','diastolic_bp','insulin','bmi','diab_pred','age','skin']\n",
    "output_columns = ['diabetes']\n",
    "x = df[input_columns].values\n",
    "y = df[output_columns].values\n",
    "spilt_test_size = 0.3\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = spilt_test_size,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff201a",
   "metadata": {},
   "source": [
    "### verify the propertion percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11646235",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{0:0.2f}% in training set'.format((len(x_train)/len(df.index))*100))\n",
    "print('{0:0.2f}% in training set'.format((len(x_test)/len(df.index))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde53f65",
   "metadata": {},
   "source": [
    "### checking True and False percentages for training and esting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training true:{0} ({1:0.2f}%)'.format(len(y_train[y_train[ : ] == 1]),len(y_train[y_train[ : ] ==\n",
    "1])/len(y_train) * 100))\n",
    "\n",
    "print('training False:{0} ({1:0.2f}%)'.format(len(y_train[y_train[ : ] == 0]),len(y_train[y_train[ : ] ==\n",
    "0])/len(y_train) * 100))\n",
    "\n",
    "print('Test true:{0} ({1:0.2f}%)'.format(len(y_test[y_test[ : ] == 1]),len(y_test[y_test[ : ] ==\n",
    "1])/len(y_train) * 100))\n",
    "\n",
    "print('Test false:{0} ({1:0.2f}%)'.format(len(y_test[y_test[ : ] == 0]),len(y_test[y_test[ : ] ==\n",
    "0])/len(y_train) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eed6a83",
   "metadata": {},
   "source": [
    "x = 10 y = 20 print(\"first is {0} and second is {1}\".format(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d5fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9a97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting no of zeros in the data\n",
    "\n",
    "total_num_preg = len(df.loc[df['num_preg']== 0])\n",
    "print(f'number of Rows missing in num_preg column is {total_num_preg}')\n",
    "\n",
    "total_glucose_conc = len(df.loc[df['glucose_conc']==0])\n",
    "print(f'number of Rows missing in glucose_conc column is {total_glucose_conc}')\n",
    "total_diastolic_bp = len(df.loc[df['diastolic_bp']==0])\n",
    "print(f'number of Rows missing in diastolic_bp column is {total_diastolic_bp}')\n",
    "total_insulin = len(df.loc[df['insulin']==0])\n",
    "print(f'number of Rows missing in insulin column is {total_insulin}')\n",
    "total_bmi = len(df.loc[df['bmi']==0])\n",
    "print(f'number of Rows missing in bmi column is {total_bmi}')\n",
    "total_diab_pred = len(df.loc[df['diab_pred']==0])\n",
    "print(f'number of Rows missing in diab_pred column is {total_diab_pred}')\n",
    "total_age = len(df.loc[df['age'] ==0])\n",
    "print(f'number of rows missing in age is {total_age}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa535dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 0 values with mean value by using simple imputer\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "fill_zeros = SimpleImputer(missing_values=0,strategy='mean')\n",
    "x_train = fill_zeros.fit_transform(x_train)\n",
    "x_test = fill_zeros.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013698c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52148195",
   "metadata": {},
   "source": [
    "## step4: Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a3d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model = GaussianNB() #creating object for GaussianNB Class\n",
    "nb_model.fit(x_train,y_train.ravel()) # Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06858a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "nb_predict_model = nb_model.predict(x_train) # Testing a model\n",
    "print(f'Predicted accuracy { metrics.accuracy_score(y_train,nb_predict_model) }') # Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "nb_predict_test = nb_model.predict(x_test)\n",
    "print(f'Predicted accuracy { metrics.accuracy_score(y_test,nb_predict_test) }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a925577",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{ metrics.confusion_matrix(y_test,nb_predict_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{ metrics.classification_report(y_test,nb_predict_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc540016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest algorithem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96654cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state=42) # creating object for\n",
    "# RandomForestClassifier class\n",
    "rf_model.fit(x_train,y_train.ravel()) # Training a machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64be031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "rf_predict_model = rf_model.predict(x_train) # Testing a model\n",
    "print(f'Predicted accuracy { metrics.accuracy_score(y_train,rf_predict_model) }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b3d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "rf_predict_test =rf_model.predict(x_test)\n",
    "print(f'Predicted accuracy { metrics.accuracy_score(y_test,rf_predict_test) }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{ metrics.confusion_matrix(y_test,rf_predict_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c788f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{ metrics.classification_report(y_test,rf_predict_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "380aa3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knearest algorithem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k_neighbor = KNeighborsClassifier()\n",
    "k_neighbor.fit(x_train,y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac724e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = k_neighbor.predict(x_test)\n",
    "print(f'Accuracy = {metrics.accuracy_score(y_test,x_pred)}')\n",
    "print(f'Confusion matrix = \\n {metrics.confusion_matrix(y_test,x_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e237238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{ metrics.classification_report(y_test,x_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a543d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "## conclusion: we had trained my model using naivebaies ,random forest and  k neighbers classication\n",
    "##  comparing those 3 algorithems random is giving good accuray and performace report\n",
    "## so we are choosing random forest algorithem for my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a0c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "support = SVC()\n",
    "support.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd37859",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = support.predict(x_test)\n",
    "print(f'Accuracy = {metrics.accuracy_score(y_test,x_pred)} ')\n",
    "print(f'Confusion matrix = \\n {metrics.confusion_matrix(y_test,x_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022134b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "standardized_data = scaler.transform(x)\n",
    "print(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7febbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_model_test = support.predict(x_test) # Testing a model\n",
    "\n",
    "input_data = [8,183,64,0,23.3,0.672,32,0.0000]\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "std_data = scaler.transform(input_data_reshaped)\n",
    "print(std_data)\n",
    "support_model_test = support.predict(std_data)\n",
    "print(support_model_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
